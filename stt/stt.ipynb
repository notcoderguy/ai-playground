{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " अर साल कितरा इस बार भी गाँव में, हुली की कहानी की तयारी आंजोरों पर थी. चारु तरफ रंग भिरंगे गुलाल की ठालिया सजी थी. और दूल नगारों की ताप गुज रही थी. लेकिन इस बार की हुली की कहानी कुछ अलक थी. गाँं के बीचो भीच बनी पुरानी हवेली, जो सालो से खामोष पडे थी. इस बार चर्चा का केंदर बन गए थी. लो कहते थे की हवेली में कोई रहस थे चबा है. और हुली के दिन वो रहस ये सामने आने अगा राथा. कहानी की शुर्वात होती है. ननी रादिका से, जो अपने दादाजी की बताए, होली की कहानी सुनकर बडी हुए थी. दादाजी हमेशा कहते, होली सिर्फ रंगो का त्योार नहीं, बरकी मन के बावों को उजागर करने का मुचा है. रादिका को यह बाते, बजपन से आखरषित करती थी. इस बार उसने थान लिया था, कि वो हवेली के राजे को सुलजाएगी.\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"small\", device=\"cuda\")\n",
    "result = model.transcribe(\"audio/output.mp3\")\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: hi\n",
      "अर साल कितरा इस बार भी गाँव में, हुली की कहानी की तयारी आंजोरों पर थी. चारु तरफ रंग भिरंगे गुलाल की ठालिया सजी थी. और दूल नगारों की ताप गुज रही थी. लेकिन इस बार की हुली की कहानी कुछ अलक थी. गाँँके भीचो भीच ब\n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(\"small\", device=\"cuda\")\n",
    "\n",
    "# load audio and pad/trim it to fit 30 seconds\n",
    "audio = whisper.load_audio(\"audio/output.mp3\")\n",
    "audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "# make log-Mel spectrogram and move to the same device as the model\n",
    "mel = whisper.log_mel_spectrogram(audio, n_mels=model.dims.n_mels).to(model.device)\n",
    "\n",
    "# detect the spoken language\n",
    "_, probs = model.detect_language(mel)\n",
    "print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
    "\n",
    "# decode the audio\n",
    "options = whisper.DecodingOptions()\n",
    "result = whisper.decode(model, mel, options)\n",
    "\n",
    "# print the recognized text\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language 'hi' with probability 0.942075\n",
      "[0.00s -> 2.82s]  तर साल कि तरा इस बार भी काँ wine kahaani, jagasis in the village.\n",
      "[3.44s -> 6.08s]  होडि की काहानी की तयारीां जोरों पर से At the time, there was a boat of horse travelers on horseback.\n",
      "[6.62s -> 9.96s]  चरु तरफ ररंग भी रंगे गुलाल की ठालिया सजी थी camsar-taring the yellow and red silk threads of the horse.\n",
      "[10.86s -> 13.56s]  अडोल नगारों की ताप गुजरही थी and the boat of the horse was in the fields.\n",
      "[13.56s -> 27.56s]  लेकिन इस बार की हुली की कहानी कुछ अलगत थी, गाँके भीचो भीच बनी पुरानी हवेली, जो सालो से खामोष पड़े थी, इस बार चर्चा का केंधर बन गए थी.\n",
      "[27.56s -> 36.56s]  लो कहते थे की हवेली में कोई रहस यह चबा है, और हुली के दिन वो रहस यह सामने आने अगा डा, कहानी की शुर्वात होती है.\n",
      "[36.56s -> 42.56s]  नन्नी रादिका से, जो अपने डादाजी की बताई, हुली की कहानी सुनकर बड़ी हुए ती.\n",
      "[42.56s -> 50.56s]  बड़ादाजी हमेशा कहते, हुली सुर्फ रंगो का तिवार नहीं, बलकी मन के बहावों को उजागर करने का मुका है.\n",
      "[50.56s -> 55.56s]  रादिका को यह बाते बजपन से आकरषित करती थी.\n",
      "[55.56s -> 62.56s]  इस बार उसने ठान लिया था, की वो हवेली के रहसे को सुलजाएगी.\n"
     ]
    }
   ],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "\n",
    "model_size = \"small\"\n",
    "\n",
    "# Run on GPU with FP16\n",
    "# model = WhisperModel(model_size, device=\"cpu\", compute_type=\"float16\")\n",
    "\n",
    "\n",
    "# or run on GPU with INT8\n",
    "# model = WhisperModel(model_size, device=\"cuda\", compute_type=\"int8_float16\")\n",
    "# or run on CPU with INT8\n",
    "model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "\n",
    "segments, info = model.transcribe(\"audio/output.mp3\", beam_size=5)\n",
    "\n",
    "print(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))\n",
    "\n",
    "for segment in segments:\n",
    "    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
